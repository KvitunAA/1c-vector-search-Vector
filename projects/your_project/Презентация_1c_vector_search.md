# Презентация: 1c-vector-search — семантический поиск по конфигурации 1С

**Для простых пользователей**

---

## Слайд 1: О чём этот проект?

**1c-vector-search** — это инструмент для **умного поиска** по коду и метаданным конфигураций 1С (ЗУП, УТ, ERP и др.).

- Ищет не по точному совпадению слов, а по **смыслу** запроса
- Работает локально (ChromaDB + SQLite), без Docker
- Интегрируется с Cursor через MCP (Model Context Protocol)

**Пример:** запрос «проведение документа реализации» найдёт соответствующие процедуры, даже если в коде нет этих точных слов.

---

## Слайд 2: Что такое модель?

**Модель** — это программа, обученная на большом объёме текста, которая «понимает» язык.

- **Модель эмбеддингов** — специальная модель, которая превращает текст в числовой вектор (набор чисел)
- Похожие по смыслу тексты дают похожие векторы
- В проекте можно использовать:
  - **Удалённый API** (LM Studio, LocalAI, OpenAI-совместимый)
  - **Локальную модель** (sentence-transformers)

**Аналогия:** модель — как переводчик, который переводит текст на «язык чисел», понятный компьютеру для сравнения.

---

## Слайд 3: Что такое вектор?

**Вектор** — упорядоченный набор чисел, как координаты точки в пространстве.

- В 2D: [3, 4] — точка на плоскости (x=3, y=4)
- В 3D: [1, 2, 3] — точка в пространстве (x=1, y=2, z=3)
- В эмбеддингах: вектор из 768 или 4096 чисел — «координаты» в многомерном пространстве

**Главное правило:** чем ближе две точки (векторы), тем ближе по смыслу то, что они представляют.

**Простой пример:**
- Точка A [1, 1] и точка B [1, 2] — близко
- Точка A [1, 1] и точка C [10, 10] — далеко  
Компьютер умеет считать «расстояние» между векторами и находить самые близкие.

---

## Слайд 4: Что такое эмбеддинг (embedding)?

**Эмбеддинг** — это превращение текста в вектор с помощью модели.

**Что делает:** берёт любой текст (фразу, код, описание) и выдаёт набор чисел — вектор. Похожие по смыслу тексты дают близкие векторы.

**Простой пример:**

| Текст | Вектор (упрощённо) |
|-------|---------------------|
| «Проведение документа» | [0.12, -0.34, 0.56, …] |
| «Запись документа в базу» | [0.11, -0.33, 0.55, …] |
| «Погода сегодня» | [-0.89, 0.21, -0.44, …] |

Первые два вектора близки → смысл близок (оба про документы). Третий далеко → другой смысл.

**Зачем:** поиск «похожего» без точного совпадения слов. Запрос «проведение реализации» найдёт код про проведение документа, даже если там нет слова «реализация».

---

## Слайд 5: Что такое семантический поиск?

**Семантический поиск** — поиск по смыслу, а не по точному совпадению слов.

**Для чего:** найти релевантные фрагменты, даже если формулировки отличаются. Обычный поиск «проведение» не найдёт «ЗаписатьДокумент»; семантический — найдёт, потому что смысл близок.

**Связь с векторными моделями:** текст (запрос и документы) превращают в векторы через модель эмбеддингов. Поиск = поиск ближайших векторов в пространстве. Чем ближе векторы, тем релевантнее результат. Без векторных моделей семантический поиск невозможен.

**Схема:** Запрос → эмбеддинг → вектор запроса → сравнение с векторами в БД → топ-N самых близких.

---

## Слайд 6: Векторы и графы — в чём разница, зачем оба

**Что такое граф?** Структура из **узлов** (объекты: справочник, документ, процедура) и **рёбер** (связи: «А ссылается на Б», «А вызывает метод Б»). Граф хранит явные связи, а не «похожесть по смыслу».

**Как применяются в проекте:** векторная БД (ChromaDB) и граф (SQLite) — **разные хранилища**. Векторы — для семантического поиска по коду и метаданным. Граф — для зависимостей: кто на кого ссылается, что что вызывает.

**Векторы vs графы:**

| Векторы | Графы |
|---------|-------|
| Поиск по смыслу («найди похожее») | Поиск по связям («кто использует», «на что ссылается») |
| Хранятся в ChromaDB | Хранятся в SQLite |
| Нужна модель эмбеддингов | Нужен парсер кода и метаданных |

**Зачем оба:** векторы находят релевантный код по запросу; граф показывает цепочки вызовов и зависимости. Вместе — полная картина: и «что похоже», и «как связано».

---

## Слайд 7: Что такое токены?

**Токен** — это минимальная единица текста для модели.

- Не всегда = одно слово: может быть часть слова, знак препинания, пробел
- Для русского/BSL: примерно **2 символа ≈ 1 токен**
- У каждой модели есть **лимит токенов** (контекстное окно)

**Пример:** фраза «Процедура Проведение()» — примерно 5–8 токенов.

**Зачем важно:** модель не может обработать текст длиннее своего лимита, поэтому длинные тексты обрезают или делят на части.

---

## Слайд 8: Что такое чанки (chunks)?

**Чанк** — это кусок текста фиксированного размера, на который делится код для индексации.

- Код 1С разбивается на части (чанки), чтобы каждая помещалась в модель
- Между соседними чанками делают **нахлёст** (overlap)

**Что такое нахлёст?** Это общая часть текста между соседними чанками — следующий чанк начинается не с «чистой» границы, а чуть раньше, захватывая конец предыдущего. **Зачем:** если важная мысль или логика оказалась на стыке двух чанков, без нахлёста она может «разрезаться» и потерять смысл. С нахлёстом эта часть попадёт в оба чанка целиком, и поиск её найдёт.

**Пример:**
- Чанк 1: строки 1–50 кода
- Чанк 2: строки 40–90 (нахлёст 10 строк)
- Чанк 3: строки 80–130 и т.д.

**Зачем:** при поиске «проведение документа» система найдёт нужный чанк и покажет соответствующий фрагмент кода.

---

## Слайд 9: Основные параметры — модель и API

**Модели:** мультиязычные (русский, BSL), для семантического поиска. Локально (sentence-transformers) или через API (LM Studio, LocalAI). Примеры: nomic — 100+ языков; paraphrase-multilingual — 50+ языков, лёгкая.

**Размерность:** задаётся моделью. 768 — компромисс качества и затрат; 4096 — больше точность, больше памяти; 384 — быстрее.

| Параметр | Что это | Пример |
|----------|---------|--------|
| **EMBEDDING_MODEL** | Имя модели эмбеддингов | `nomic-embed-text-v2-moe` или `paraphrase-multilingual-MiniLM-L12-v2` |
| **EMBEDDING_API_BASE** | URL API (LM Studio, LocalAI и т.п.). Пусто = локальная модель | `http://192.168.0.1:1234/v1` |
| **EMBEDDING_DIMENSION** | Размерность вектора (зависит от модели) | `768` (nomic), `384` (MiniLM), `4096` (Qwen3) |
| **EMBEDDING_API_KEY** | Ключ API. Для локальных серверов часто `dummy` | `dummy` |

---

## Слайд 10: Параметры токенов и чанков

| Параметр | Что это | Рекомендация |
|----------|---------|--------------|
| **EMBEDDING_MAX_TOKENS** | Макс. токенов на вход модели. Если задан — автоматически считается макс. символов (×2) | `512` для nomic |
| **CHUNK_MAX_TOKENS** | Макс. токенов в одном чанке кода | `512` (~1024 символов) |
| **CHUNK_OVERLAP_TOKENS** | Нахлёст между чанками в токенах | `100` (по умолчанию) |
| **CHUNK_MAX_CHARS** | Альтернатива: макс. символов в чанке | Если не задан CHUNK_MAX_TOKENS |

**Коэффициент:** для BSL/русского ≈ **2 символа = 1 токен**.

---

## Слайд 11: Пример настроек для nomic-embed-text-v2-moe

**Почему nomic подходит для 1С:** мультиязычная (100+ языков, русский, BSL), хорошее качество семантического поиска, 512 токенов — хватает для типичных чанков кода, открытая модель (можно запускать локально).

**Требования к ПК:** ~475M параметров, файл модели ~2 ГБ. RAM: минимум 4–8 ГБ свободной памяти. Работает на CPU (через LM Studio, GGUF); GPU не обязателен, но ускоряет индексацию.

```env
EMBEDDING_API_BASE=http://192.168.0.1:1234/v1
EMBEDDING_MODEL=text-embedding-nomic-embed-text-v2-moe
EMBEDDING_DIMENSION=768
EMBEDDING_MAX_TOKENS=512
CHUNK_MAX_TOKENS=512
CHUNK_OVERLAP_TOKENS=100
```

- Context Length модели: 512 токенов
- Чанки по 512 токенов (~1024 символов)
- Нахлёст 100 токенов для сохранения контекста на стыках

---

## Слайд 12: Пути и хранилища

| Параметр | Что это | Пример |
|----------|---------|--------|
| **CONFIG_PATH** | Путь к выгрузке конфигурации 1С (где лежит `Configuration.xml`) | `C:\1C\Config\ZUP` |
| **VECTORDB_PATH** | Папка векторной БД (ChromaDB) | `projects/Vector/vectordb` |
| **GRAPHDB_PATH** | Файл графа зависимостей (SQLite) | `projects/Vector/graphdb/graph.db` |

---

## Слайд 13: Что умеет система?

| Инструмент | Назначение |
|------------|------------|
| **search_1c_code** | Поиск процедур и функций по описанию на естественном языке |
| **search_1c_metadata** | Поиск справочников, документов, регистров по названию/описанию |
| **search_1c_forms** | Поиск форм по описанию |
| **find_1c_method_usage** | Где вызывается указанный метод |
| **search_by_object_name** | Полная информация об объекте |
| **graph_dependencies** | Кто ссылается на объект |
| **graph_references** | На что ссылается объект |

---

## Слайд 14: Как это работает (схема)

```
1. ВЕКТОРЫ (ChromaDB):
   Индексация: Код 1С → чанки → модель → векторы → ChromaDB
   Поиск: Запрос → эмбеддинг → сравнение с ChromaDB → топ-N похожих

2. ГРАФ (SQLite):
   Индексация: Метаданные и код → парсер → узлы и рёбра (кто на кого ссылается)
   Поиск: graph_dependencies, graph_references — обход связей

*Презентация подготовлена на основе README.md и документации проекта 1c-vector-search.*
